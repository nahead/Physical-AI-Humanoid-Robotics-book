"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[150],{2124:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"bookSidebar":[{"type":"category","label":"Module 1: ROS 2","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/module1-ros/nodes-topics-services","label":"ROS 2 Nodes, Topics, and Services","docId":"module1-ros/nodes-topics-services","unlisted":false},{"type":"link","href":"/ur/docs/module1-ros/python-rclpy-bridge","label":"Bridging Python Agents to ROS Controllers using rclpy","docId":"module1-ros/python-rclpy-bridge","unlisted":false},{"type":"link","href":"/ur/docs/module1-ros/urdf-humanoids","label":"Understanding URDF (Unified Robot Description Format) for Humanoids","docId":"module1-ros/urdf-humanoids","unlisted":false},{"type":"link","href":"/ur/docs/module1-ros/intro-to-ros","label":"Introduction to ROS 2","docId":"module1-ros/intro-to-ros","unlisted":false}],"href":"/ur/docs/category/module-1-ros-2"},{"type":"category","label":"Module 2: Simulation","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/module2-simulation/gazebo-physics","label":"Simulating Physics, Gravity, and Collisions in Gazebo","docId":"module2-simulation/gazebo-physics","unlisted":false},{"type":"link","href":"/ur/docs/module2-simulation/unity-rendering-hri","label":"High-Fidelity Rendering and Human-Robot Interaction in Unity","docId":"module2-simulation/unity-rendering-hri","unlisted":false},{"type":"link","href":"/ur/docs/module2-simulation/sensor-simulation","label":"Sensor Simulation: LiDAR, Depth Cameras, IMUs","docId":"module2-simulation/sensor-simulation","unlisted":false},{"type":"link","href":"/ur/docs/module2-simulation/intro-to-simulation","label":"Introduction to Digital Twin Simulation","docId":"module2-simulation/intro-to-simulation","unlisted":false}],"href":"/ur/docs/category/module-2-simulation"},{"type":"category","label":"Module 3: NVIDIA Isaac","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/module3-isaac/isaac-ros-vslam-perception","label":"Isaac ROS: Hardware-Accelerated VSLAM & Perception","docId":"module3-isaac/isaac-ros-vslam-perception","unlisted":false},{"type":"link","href":"/ur/docs/module3-isaac/nav2-humanoid-pathing","label":"Nav2: Path Planning for Bipedal Humanoid Movement","docId":"module3-isaac/nav2-humanoid-pathing","unlisted":false},{"type":"link","href":"/ur/docs/module3-isaac/isaac-sim-photorealistic","label":"NVIDIA Isaac Sim: Photorealistic Simulation & Synthetic Data","docId":"module3-isaac/isaac-sim-photorealistic","unlisted":false}],"href":"/ur/docs/category/module-3-nvidia-isaac"},{"type":"category","label":"Module 4: VLA","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/module4-vla/whisper-voice-to-action","label":"Voice-to-Action with OpenAI Whisper","docId":"module4-vla/whisper-voice-to-action","unlisted":false},{"type":"link","href":"/ur/docs/module4-vla/capstone-project","label":"Capstone Project: Autonomous Humanoid (Voice \u2192 Plan \u2192 Navigation \u2192 Vision \u2192 Manipulation)","docId":"module4-vla/capstone-project","unlisted":false},{"type":"link","href":"/ur/docs/module4-vla/vla-pipelines-overview","label":"VLA Pipelines Overview","docId":"module4-vla/vla-pipelines-overview","unlisted":false}],"href":"/ur/docs/category/module-4-vla"}]},"docs":{"module1-ros/intro-to-ros":{"id":"module1-ros/intro-to-ros","title":"Introduction to ROS 2","description":"The Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms. ROS 2 is the latest iteration of this framework, re-architected to address the limitations of ROS 1, particularly in areas like real-time control, multi-robot systems, and embedded platforms.","sidebar":"bookSidebar"},"module1-ros/nodes-topics-services":{"id":"module1-ros/nodes-topics-services","title":"ROS 2 Nodes, Topics, and Services","description":"In ROS 2, the communication system is built around a decentralized architecture where individual processes, called nodes, interact with each other through various communication patterns. This modularity is a cornerstone of ROS, allowing for flexible and robust robot software development. This chapter will delve into the core communication mechanisms: Topics, Services, and Actions.","sidebar":"bookSidebar"},"module1-ros/python-rclpy-bridge":{"id":"module1-ros/python-rclpy-bridge","title":"Bridging Python Agents to ROS Controllers using rclpy","description":"Python is a popular language in robotics due to its simplicity, extensive libraries for AI/ML, and rapid prototyping capabilities. rclpy is the Python client library for ROS 2, providing a convenient and powerful way to integrate Python-based agents and algorithms with the ROS 2 ecosystem. This chapter explores how to effectively use rclpy to bridge your Python code with ROS 2 controllers and components.","sidebar":"bookSidebar"},"module1-ros/urdf-humanoids":{"id":"module1-ros/urdf-humanoids","title":"Understanding URDF (Unified Robot Description Format) for Humanoids","description":"The Unified Robot Description Format (URDF) is an XML format used in ROS to describe all elements of a robot. It\'s a crucial component for defining the kinematics, dynamics, visual appearance, and collision properties of a robot, enabling simulation, visualization, and motion planning. This chapter focuses on applying URDF to describe humanoid robots, which present unique challenges due to their complex articulated structure.","sidebar":"bookSidebar"},"module2-simulation/gazebo-physics":{"id":"module2-simulation/gazebo-physics","title":"Simulating Physics, Gravity, and Collisions in Gazebo","description":"Gazebo is a powerful 3D robot simulator that accurately models the physics of the real world. It allows roboticists to test algorithms, design robots, and perform various experiments in a safe, repeatable virtual environment. Understanding how Gazebo handles physics, gravity, and collisions is fundamental to creating realistic and reliable robotic simulations.","sidebar":"bookSidebar"},"module2-simulation/intro-to-simulation":{"id":"module2-simulation/intro-to-simulation","title":"Introduction to Digital Twin Simulation","description":"The concept of a \\"digital twin\\" is revolutionizing how we design, develop, and deploy robotic systems. A digital twin is a virtual representation of a physical object or system, continuously updated with data from its real-world counterpart. In robotics, this translates to creating high-fidelity simulations that mirror the behavior of real robots and their operating environments. This module will introduce the fundamentals of digital twin simulation, focusing on its application in robotics using tools like Gazebo and Unity.","sidebar":"bookSidebar"},"module2-simulation/sensor-simulation":{"id":"module2-simulation/sensor-simulation","title":"Sensor Simulation: LiDAR, Depth Cameras, IMUs","description":"Robots rely heavily on sensors to perceive their environment and their own state. Accurate sensor simulation is crucial for developing robust perception, navigation, and control algorithms without the need for expensive and time-consuming real-world hardware. This chapter focuses on simulating common robotics sensors like LiDAR, Depth Cameras, and Inertial Measurement Units (IMUs) in Gazebo and Unity, and how to integrate their data into the ROS 2 ecosystem.","sidebar":"bookSidebar"},"module2-simulation/unity-rendering-hri":{"id":"module2-simulation/unity-rendering-hri","title":"High-Fidelity Rendering and Human-Robot Interaction in Unity","description":"Unity is a powerful cross-platform game engine that has found increasing utility in robotics simulation due to its advanced rendering capabilities, robust physics engine, and rich ecosystem for interactive experiences. This chapter explores how to leverage Unity for high-fidelity visualization, realistic environment creation, and engaging human-robot interaction (HRI) simulations.","sidebar":"bookSidebar"},"module3-isaac/isaac-ros-vslam-perception":{"id":"module3-isaac/isaac-ros-vslam-perception","title":"Isaac ROS: Hardware-Accelerated VSLAM & Perception","description":"NVIDIA Isaac ROS is a collection of hardware-accelerated packages for ROS 2, designed to significantly boost the performance of robotics applications, especially in areas like Visual SLAM (Simultaneous Localization and Mapping), perception, and AI inference. Leveraging NVIDIA GPUs and other hardware accelerators, Isaac ROS provides optimized building blocks that enable robots to process sensor data faster and make intelligent decisions in real-time.","sidebar":"bookSidebar"},"module3-isaac/isaac-sim-photorealistic":{"id":"module3-isaac/isaac-sim-photorealistic","title":"NVIDIA Isaac Sim: Photorealistic Simulation & Synthetic Data","description":"NVIDIA Isaac Sim is a powerful, GPU-accelerated robotics simulation platform built on NVIDIA Omniverse. It stands out for its photorealistic rendering, accurate physics, and advanced capabilities for generating synthetic data. These features are crucial for developing and training AI models for perception, manipulation, and navigation in complex robotic systems. This chapter explores the core aspects of Isaac Sim, focusing on its photorealistic environments and its role in synthetic data generation.","sidebar":"bookSidebar"},"module3-isaac/nav2-humanoid-pathing":{"id":"module3-isaac/nav2-humanoid-pathing","title":"Nav2: Path Planning for Bipedal Humanoid Movement","description":"Navigation is a cornerstone of autonomous robotics, enabling robots to move from a starting point to a goal while avoiding obstacles. ROS 2\'s Navigation2 (Nav2) stack provides a comprehensive framework for this, offering modules for localization, global and local path planning, and controller execution. While Nav2 is commonly used with wheeled robots, adapting it for complex bipedal humanoid movement presents unique challenges and opportunities.","sidebar":"bookSidebar"},"module4-vla/capstone-project":{"id":"module4-vla/capstone-project","title":"Capstone Project: Autonomous Humanoid (Voice \u2192 Plan \u2192 Navigation \u2192 Vision \u2192 Manipulation)","description":"This capstone project integrates the concepts and technologies learned throughout the book into a comprehensive Vision-Language-Action (VLA) pipeline for an autonomous humanoid robot. The goal is to enable the humanoid to understand high-level voice commands, plan its actions, navigate an environment, perceive objects, and execute manipulation tasks. This project emphasizes the practical application of ROS 2, simulation (Gazebo/Isaac Sim), perception (Isaac ROS), and LLM-driven intelligence.","sidebar":"bookSidebar"},"module4-vla/vla-pipelines-overview":{"id":"module4-vla/vla-pipelines-overview","title":"VLA Pipelines Overview","description":"Vision-Language-Action (VLA) pipelines represent a cutting-edge paradigm in robotics, enabling robots to interpret natural language commands, understand their visual surroundings, and execute complex physical actions. This integration of perception, cognition, and action is crucial for creating truly intelligent and adaptable autonomous systems that can interact intuitively with humans and perform tasks in unstructured environments.","sidebar":"bookSidebar"},"module4-vla/whisper-voice-to-action":{"id":"module4-vla/whisper-voice-to-action","title":"Voice-to-Action with OpenAI Whisper","description":"Natural language understanding is a critical component for intuitive human-robot interaction. Enabling robots to accurately transcribe spoken commands and then act upon them bridges the gap between human intent and robotic execution. OpenAI Whisper, a robust automatic speech recognition (ASR) system, provides an excellent foundation for converting human voice commands into text that can then be processed by Large Language Models (LLMs) and translated into robot actions.","sidebar":"bookSidebar"}}}}')}}]);